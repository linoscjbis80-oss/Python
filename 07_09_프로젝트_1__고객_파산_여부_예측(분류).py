# -*- coding: utf-8 -*-
"""07-09. 프로젝트 1_ 고객 파산 여부 예측(분류).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10gUqkt_aEveAINbijPXBq3dSP_u5bhSr

#<span style="color:orange">분류 모델 프로젝트 : 고객 파산 여부 예측</span>

## 1. Pycaret 세팅
"""

# pycaret 라이브러리를 설치합니다.
!pip install pycaret

from pycaret.utils.generic import enable_colab
enable_colab()
# colab에서 사용가능한 환경을 만들어줌

"""## 2. Pycaret을 이용한 분류 모델

- `pycaret.classification`을 통해 분류 모델을 쉽게 구현할 수 있습니다.


- 이번 예제는 "Binary Classification(이진 분류)" 모델에 대한 실습을 진행합니다.


- Pycaret은 14개의 분류 모델을 기본적으로 제공하며, 학습을 위해 정해야하는 여러가지 세팅들을 자동으로 해줍니다. (e.g. hyper-parameter tuning)


- 분류 모델에 대한 전처리 및 Feature Engineering을 직접 수행해보고, 성능 향상을 시켜봅니다.

# 3. 프로젝트에 사용할 데이터셋

**Default of Credit Card Clients Dataset**을 사용합니다.
이 데이터셋은 2005년 4월부터 2005년 9월까지 대만에서 발생한 신용카드 거래 내역을 포함하고 있습니다.
총 24,000개의 데이터가 25개의 feature로 구성되어 있습니다.

아래 데이터의 Feature에 대한 설명을 첨부하였습니다.

- **ID:** ID of each client
- **LIMIT_BAL:** Amount of given credit in NT dollars (includes individual and family/supplementary credit)
- **SEX:** Gender (1=male, 2=female)
- **EDUCATION:** (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
- **MARRIAGE:** Marital status (1=married, 2=single, 3=others)
- **AGE:** Age in years
- **PAY_0 to PAY_6:** Repayment status by n months ago (PAY_0 = last month ... PAY_6 = 6 months ago) (Labels: -1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)
- **BILL_AMT1 to BILL_AMT6:** Amount of bill statement by n months ago ( BILL_AMT1 = last_month .. BILL_AMT6 = 6 months ago)
- **PAY_AMT1 to PAY_AMT6:** Amount of payment by n months ago ( BILL_AMT1 = last_month .. BILL_AMT6 = 6 months ago)
- **default:** Default payment (1=yes, 0=no) `Target Column`

#### Reference:
Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science.

원본 설명은 다음 링크를 참고하세요.\[  __[원본](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)__ \]

# 4. 데이터 불러오기

- `get_data()` 함수를 통해 데이터를 불러옵니다.
"""

!pip install pycaret[analysis]

"""- EDA : Exploratory Data Analysis
- 통계량(mean, median, mode, skewness...), 상관관계(corrlation coefficient),... =>시각화
"""

# pycaret에서 get_data 함수를 불러옵니다.
from pycaret.datasets import get_data

# profile option을 통해 Pandas Profile을 사용합니다.
dataset=get_data('credit')

dataset

dataset.duplicated(subset='MARRIAGE')

dataset[dataset.MARRIAGE.duplicated()]

dataset[dataset.duplicated(subset='MARRIAGE')]

dataset[dataset.duplicated()]
# 중복된 행(True) 출력
# default : keep : 'first'
# DataFrame.duplicated(subset=???, keep='???') 형식

## 불러온 데이터셋의 정보를 살펴봅니다.
dataset.info()

dataset.isnull().sum()

"""## 5. 학습을 위한 데이터 전처리"""

# 8 : 2로 train - test split을 합니다.
data=dataset.sample(frac=0.8,random_state=231)
data_unseen=dataset.drop(data.index)
data.reset_index(inplace=True, drop=True)
data_unseen.reset_index(inplace=True,drop=True)

print('Data for Modeling: ' + str(data.shape))
print('Unseen Data For Predictions: ' + str(data_unseen.shape))

"""## 6. 학습을 위한 Pycaret 세팅

- Pycaret을 통한 프로젝트를 진행하기 위해서는 `setup()` 함수를 통해 학습 환경 세팅을 해야합니다.


- `pycaret.classification`의 `setup()` 함수는 input data인 DataFrame과 target value 지정이 반드시 필요합니다.


- `setup()`가 실행되면 내부에서 자동으로 여러가지 세팅을 완료하기 때문에, 사용자에게 이를 검증받기 위해서 `enter` 또는 `quit`을 입력받습니다. 무언가가 잘못되었다면, `quit`을 입력하여 종료하고, 그렇지 않다면 `enter`를 통해 다음으로 진행합니다.


- `setup()` 함수에서 여러가지 전처리 작업들을 수행할 수 있습니다. normalization, transformation, bin_numeric_features 등 다양한 전처리 기능을 제공합니다.
"""

# classification 함수를 모두 불러옵니다.
from pycaret.classification import *

# setup
# Feature Engineering
clf = setup(data=data,target="default",
            normalize=True,
            remove_multicollinearity=True, multicollinearity_threshold=0.9,
            bin_numeric_features=["LIMIT_BAL","AGE"]
            )
# normalize (numeric feature들을 0~1 값으로 변경)
# remove multicollinearity 다중공산성 제거 (상관관계가 높은 feature들중 일부를 제거 기준 상관계수=0.9)
# multicollinearity_threshold=0.9 이면 0.9이상의 상관관계 제거
# bin_numeric_features 매개변수 이용해서 구간을 나눠줌(numeric feature들을 categorical feature로 변경)

"""- `compare_models()`를 실행하면, `setup()` 함수가 세팅했던 상태로 기본으로 정해진 분류 모델을 모두 수행합니다.


- 모델을 직접 지정하지 않는다면, 14가지의 기본 분류 모델을 모두 수행하여 비교하는 table을 출력합니다.


- 성능 비교를 위해 여러가지 측정 지표(metric)을 출력합니다. Accuracy, AUC, Recall, Precision, F1 score, Kappa, MCC, Training Time을 출력합니다.



- 각 지표에 대한 자세한 내용은 다음 과정에서 다룹니다. 이번 과정에서는 "Accuracy"만을 다루겠습니다.
> `Accuracy(정확도)` 는 전체 데이터 중에 맞은 개수의 비율입니다.
"""

top3 = compare_models(n_select=3)

# top3 출력
print(top3)

"""## 8. 특정 머신러닝 모델 사용해보기

- `create_model()` 함수를 통해서 Pycaret이 제공하는 18개의 모델 중 원하는 모델을 학습에 사용할 수 있습니다.


- `models()` 함수를 사용하면 지원하는 모든 모델들의 목록과 reference를 볼 수 있습니다.


- baseline으로 가장 많이 사용되는 분류 모델인 RandomForestClassifier를 다뤄보도록 하겠습니다.

RandomForest Classifier with Cross-Validation
"""

models()
# Turbo는 True로 하는 경우에, 학습 시간이 너무 오래걸리면, 생략하고 다음으로 넘어가는 것을 의미한다.

# trining RandomForestClassifier with fold 5
rf =create_model('rf',fold=10) # k-fold : 3~10(k)
# fold =10 무작위로 데이터 비율맞게 선정해 10번 트레이닝

"""## 9. 모델 성능 개선하기

- 학습한 모델의 성능을 개선하고 싶을 때, **hyper-parameter tuning**을 할 수 있습니다.


- PyCaret에서 `tune_model()` 함수를 이용하여 hyper-parameter tuning을 진행합니다.


- PyCaret은 기본적으로 `Random Grid Search`를 사용합니다.

- RandomForestClassifier

: n_estimator -> 몇 개의 DecisionTree를 묶어서 쓸거냐.

: max_depth -> 각 DecisionTreeClassifier의 최대깊이를 얼마로 할 것이냐.
"""

tuned_rf=tune_model(rf,n_iter=30)
# n_iter 트레이닝 횟수

tuned_rf2 =tune_model(rf,optimize='AUC') # auc를 가장 좋게 튜닝함

# 학습된 parameter 출력
plot_model(tuned_rf2,'parameter') # 세팅된 파라미터 출력

"""## 10. 모델 앙상블을 통해 성능 올리기

- `ensemble_model()` 함수를 사용해서 여러 모델들을 통해 집단 지성을 이뤄냅니다(?)


- Weak learner들의 합으로 robust하게 성능 향상을 얻을 수 있습니다.


- "Bagging"과 "Boosting" 방법을 모두 사용합니다.

### 10.1 Bagging and Boosting : `ensemble_model()`

- Bagging : weak learner(하나하나의 학습모델)들의 parallei하게(한번에) 학습을  시켜서, avrage를 모델의 성능으로 평가.

- Boosting : weak learner들을 sequential하게 학습을 시켜서, 결과를 점차 좋게 만드는 방법.
"""

ensembled=ensemble_model(rf,n_estimators=15) # 15개의 RF모델의 성능 평균
# n_estimators 트리갯수

"""### 10.2 Blending Model : `blend_model()`

- Bagging이나 boosting은 단일 모델(weak learner)들을모아서 성능 향상을 시켰다면, blending은 다른 모델(heterogeneous)들을 모아서 성능을 향상시키는 방법

- soft/hard
"""

# train individual models to blend
# verbose 옵션 : 상세한 로깅을 출력할지 말지 조정하는 파라미터
lightgbm=create_model("lightgbm",verbose=False) # lightgbm
rf=create_model("rf",verbose=False) # RandomForest
lr=create_model("lr",verbose=False) # LogisticRegression

# blend individual models, soft voting
blend_soft = blend_models([lightgbm,rf,lr],method='soft') # soft -> 다같이 합쳐서
# top3인 모델들을 다같이 합쳐서 모델을 만드니 성능이 rf만 썼을때보다 좋음

"""- 모델별 편차가 큰경우 soft
- 모델별 편차가 작은경우 hard
"""

# blend individual models, hard voting
blend_hard=blend_models([lightgbm,lr,rf],method='hard')
# hard ->각각의 모델, auc값이 없음. 1개의 모델을 찍기때문에

# blend top3 models from compare_models
# Recreate the top 3 models explicitly before blending
top3_models = [create_model('gbc' if model.__class__.__name__ == 'GradientBoostingClassifier' else ('ada' if model.__class__.__name__ == 'AdaBoostClassifier' else 'lightgbm' if model.__class__.__name__ == 'LGBMClassifier' else model.__class__.__name__.lower()), verbose=False) for model in top3]
blend_model_top3 = blend_models(top3_models)

# top3 출력
print(blend_model_top3)

"""## 11. 학습 결과 시각화하기

- `plot_model()` 함수를 통해서 실험 결과를 시각화할 수 있습니다.


- 시각화 기법으로는 AUC Plot, Precision-Recall Curve, Feature Importance Plot, Confusion Matrix을 사용하여 학습에 대한 성능 평가를 쉽게 확인할 수 있습니다.
"""

# AUC Plot ## Area Under ROC-Curve
plot_model(blend_soft, plot='auc')

# Precision-Recall Curve
# auc 반대 (맞아야하는데 틀린것, 틀려야하는데 맞은것)
# TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative)
plot_model(blend_soft, plot='pr')
# X축 : 실제, Y축 : 예측
# Average Precision : PR Curve의 아래 면적 부분의 넓이 (점선 부분이 교차하는지점 = 가장 성능 좋을떄)

"""예시에서도 느꼈겠지만 Precision 하고 Recall은 반비례 관계일 수 밖에 없다

음주 단속 같이 무조건 한 놈도 안빼고 잡겠다고 Recall을 올리면 억울한 사람들이 생겨 Precision은 낮아진다

그렇다고 확실한 놈만 잡겠다 Precision을 높이면 죄가 있는데 통과하는 놈들이 생겨 Recall은 낮아진다
[출처] 분류 성능 평가 지표 Confusion Matrix (Precision , Recall, Accuracy, F1 Score, AUC, ROC Curve, FPR)|작성자 하람 Haram
"""

# Feature Importance Plot -> Tree model(DecisionTree, RandomFroest, xhboost, lightgbm)
plot_model(tuned_rf, plot='feature')

# Confusion Matrix (오류 메트릭스)
plot_model(blend_soft, plot='confusion_matrix')

"""## 12. 학습 모델 결정

- PyCaret을 이용하여 머신러닝 프로젝트를 수행할땐, `setup()` 함수로 학습 전략을 설정한 다음, `compare_models()`를 통해서 학습에 필요한 모델들을 선정하고, `finalize_model()` 함수를 통해서 최종 모델을 결정합니다.


- `finalize_model()`을 통해서 결정된 모델은 최종 production에 사용됩니다. 이 때 '모든 데이터'를 이용해 학습을 재개하고, 이를 통해 최종 성능을 평가합니다.


- '모든 데이터'를 이용해 다시 학습을 진행한다는 의미는, cross-vaildation을 통해 training data중에 70%만 학습했던 모델을 training data 100%에 대해 학습을 하겠다는 의미입니다.
"""

# production을 위해 SoftVoting Blender 모델에 재학습 및 최종 모델을 결정합니다.
finalize_model=finalize_model(blend_soft)

"""## 13. 학습한 모델 테스트하기

- `predict_model()` 함수를 이용하여, 테스트를 위해 남겨둔 20%의 데이터로 학습된 모델을 평가합니다.


- 머신러닝의 목표는 실제로 학습하지 않은 데이터(`data_unseen`)에 대한 예측이기 때문에, test data를 통한 평가가 가장 중요합니다!
"""

# predict_model 함수의 결과는 DataFrame으로 출력됩니다.
unseen_prediction=predict_model(finalize_model,data=data_unseen)
unseen_prediction

# pycaret.utils.check_metric 함수를 사용하여, 원하는 조건으로 학습한 모델을 테스트할 수 있습니다.
from pycaret.utils.generic import check_metric
check_metric(unseen_prediction["default"],
             unseen_prediction['prediction_label'],metric='Accuracy')

# AUC
from pycaret.utils.generic import check_metric
check_metric(unseen_prediction["default"],
             unseen_prediction['prediction_label'],metric='AUC')

# ROC 커브와 x축이 이루고 있는 면적의 넓이를 AUC(Area Under Curve)

"""- top3 model들에 대해서 tuning을 따로 한 다음 blending
- 각 모델별 특징을 파악해서 전체 성능를 피드백하고, feature engineering을 다시 해보는 것
- Accuracy, AUC, F1 score 같은 다양한 지표를 기준으로 tuning을 해보는
"""